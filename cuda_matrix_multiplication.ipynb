{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kowsar-Hossain/Parallel_Processing_Lab/blob/main/cuda_matrix_multiplication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU3p_BlUnrDJ",
        "outputId": "08201f51-ea23-4fe4-f96b-c1e6855e7834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile matrix.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void matrixMul(float *A, float *B, float *R, int M, int N, int P, int batchOffset) {\n",
        "  int k = threadIdx.x + batchOffset;\n",
        "  float *a = A + k * M * N;\n",
        "  float *b = B + k * N * P;\n",
        "  float *r = R + k * M * P;\n",
        "for(int outer = 0; outer < 100; outer++) {\n",
        "  for(int i = 0; i < M; i++) {\n",
        "    for(int l = 0; l < P; l++) {\n",
        "      r[i * P + l] = 0.0f; // explicitly set to 0\n",
        "      for(int j = 0; j < N; j++) {\n",
        "        r[i * P + l] += a[i * N + j] * b[j * P + l];\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "}\n",
        "\n",
        "// print the first matrix only\n",
        "void printMatrix(float *A, int M, int N) {\n",
        "  for(int i = 0; i < M; i++) {\n",
        "    for(int j = 0; j < N; j++) {\n",
        "      printf(\"%.0f \", A[i * N + j]);\n",
        "    }\n",
        "    cout<<endl;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char* argv[]) {\n",
        "  int threads = atoi(argv[1]);\n",
        "  int K = atoi(argv[2]);\n",
        "  int M = atoi(argv[3]);\n",
        "  int N = atoi(argv[4]);\n",
        "  int P = atoi(argv[5]);\n",
        "\n",
        "  //int K = 2, M = 2, N = 2, P = 2;\n",
        "\n",
        "  int size_of_a = K * M * N;\n",
        "  int size_of_b = K * N * P;\n",
        "  int size_of_r = K * M * P;\n",
        "\n",
        "  float *h_A = (float*)malloc(size_of_a * sizeof(float));\n",
        "  float *h_B = (float*)malloc(size_of_b * sizeof(float));\n",
        "  float *h_R = (float*)malloc(size_of_r * sizeof(float));\n",
        "\n",
        "  for(int i = 0; i < size_of_a; i++) {\n",
        "    h_A[i] = rand() % 10;\n",
        "  }\n",
        "  for(int i = 0; i < size_of_b; i++) {\n",
        "    h_B[i] = rand() % 10;\n",
        "  }\n",
        "  float *d_A;\n",
        "  cudaMalloc(&d_A, size_of_a * sizeof(float));\n",
        "  cudaMemcpy(d_A, h_A, size_of_a * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  float *d_B;\n",
        "  cudaMalloc(&d_B, size_of_b * sizeof(float));\n",
        "  cudaMemcpy(d_B, h_B, size_of_b * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  float *d_R;\n",
        "  cudaMalloc(&d_R, size_of_r * sizeof(float));\n",
        "  cudaMemset(d_R, 0, size_of_r * sizeof(float));\n",
        "\n",
        "  int remainingMatrices = K;\n",
        "  int batchOffset = 0;\n",
        "\n",
        "  while(remainingMatrices > 0) {\n",
        "    int currentBatchSize = min(remainingMatrices, threads);\n",
        "    matrixMul<<<1, currentBatchSize>>>(d_A, d_B, d_R, M, N, P, batchOffset);\n",
        "    cudaDeviceSynchronize();\n",
        "    remainingMatrices -= currentBatchSize;\n",
        "    batchOffset += currentBatchSize;\n",
        "  }\n",
        "\n",
        "  cudaMemcpy(h_R, d_R, size_of_r * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cout<<\"Matrix A[0]:\"<<endl;\n",
        "  printMatrix(h_A, M, N);\n",
        "  cout<<\"Matrix B[0]:\"<<endl;\n",
        "  printMatrix(h_B, N, P);\n",
        "  cout<<\"Matrix R[0]:\"<<endl;\n",
        "  printMatrix(h_R, M, P);\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_B);\n",
        "  cudaFree(d_R);\n",
        "  free(h_A);\n",
        "  free(h_B);\n",
        "  free(h_R);\n",
        "  return 0;\n",
        "}\n",
        "\n",
        "//!nvcc -arch=sm_75 matrix.cu -o matrix\n",
        "//!time ./matrix 400 2 2 2 2 > output.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 matrix.cu -o matrix"
      ],
      "metadata": {
        "id": "AdWWlf9tQi-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!time ./matrix 400 2 2 2 2 > output.txt"
      ],
      "metadata": {
        "id": "JI4CN5K6I7Xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87bed1fa-1192-4804-d87b-be3d382accc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t0m0.169s\n",
            "user\t0m0.021s\n",
            "sys\t0m0.107s\n"
          ]
        }
      ]
    }
  ]
}